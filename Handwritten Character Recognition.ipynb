{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2545529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b0bc7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "        Calculates the sigmoid value for any vector/matrix/scaler.\n",
    "    '''\n",
    "    z = np.array(z);\n",
    "    g = np.zeros(z.shape);\n",
    "    g = 1/(1 + np.exp(-z));\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "388edd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionLR(theta,X,y,lamda):\n",
    "    '''\n",
    "        Cost Function\n",
    "\n",
    "        This function computes the cost for implementing logistic regression and contains\n",
    "        the gradient descent implementation too.\n",
    "\n",
    "        The code has been vectorised and uses regularisation using the regularisation parameter 'lambda_'\n",
    "        as an argument.\n",
    "    '''\n",
    "    theta = theta.reshape((theta.size, 1))\n",
    "    m = y.size\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    J = np.mean(-y * np.log(h) - (1 - y) * np.log(1 - h))\n",
    "    J += np.square(theta[1:]).sum() * lamda / 2 / m\n",
    "    grad = X.T.dot(h - y) / m\n",
    "    grad[1:] = grad[1:] + lamda * theta[1:] / m\n",
    "    return J, grad.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "79a5d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X,y,num_labels,lambda_):\n",
    "    '''\n",
    "        ONEVSALL trains multiple logistic regression classifiers and returns all\n",
    "        the classifiers in a matrix all_theta, where the i-th row of all_theta \n",
    "        corresponds to the classifier for label i\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    all_theta = np.zeros((num_labels,n+1));\n",
    "    \n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1);\n",
    "    \n",
    "    cost_function = lambda p, y: costFunctionLR(p, X, y, lambda_)[0]\n",
    "    grad_function = lambda p, y: costFunctionLR(p, X, y, lambda_)[1]\n",
    "        \n",
    "    for i in range(1, num_labels + 1):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        all_theta[i - 1, :] = fmin_cg(cost_function, initial_theta, fprime=grad_function,\n",
    "                                      args=(np.where((y == i), 1, 0),), maxiter=100, disp=False)\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "6946d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta1, theta2, X):\n",
    "    '''\n",
    "        Neural Network Implementation given trained classifiers and corresponding\n",
    "        parameter vector theta1 and theta2 between the given layers.\n",
    "        \n",
    "        theta1 = (25 X 401)\n",
    "        theta2 = (10 X 26)\n",
    "        X = (5000 X 400)\n",
    "    '''\n",
    "    m = X.shape[0];\n",
    "    num_labels = Theta2.shape[0];\n",
    "    \n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1);\n",
    "    \n",
    "    l1 = sigmoid(X@Theta1.T);\n",
    "    l1 = np.concatenate([np.ones((m, 1)), l1], axis=1);\n",
    "    \n",
    "    return np.argmax(sigmoid(l1@theta2.T), axis=1) + 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "388a6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    '''\n",
    "        Returns the prediction vector without nn implementation\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1);\n",
    "    \n",
    "    return np.argmax(sigmoid(X@all_theta.T), axis=1) + 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "56180ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cost Function\n",
    "\n",
    "#test parameters\n",
    "theta_t = np.array([-2,-1,1,2]).reshape(-1,1);\n",
    "X_t = np.array(np.hstack((np.ones((5,1)), np.arange(1,16).reshape(3,5).T/10)));\n",
    "y_t = np.array([1,0,1,0,1]).reshape(-1,1);\n",
    "lambda_t = 3;\n",
    "\n",
    "cost, grad = costFunctionLR(theta_t, X_t, y_t, lambda_t);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "9a1219d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5348193961097443\n"
     ]
    }
   ],
   "source": [
    "# Cost computed by the cost function\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09816791",
   "metadata": {},
   "source": [
    "Expected cost: 2.534819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "936b1faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14656137 -0.54855841  0.72472227  1.39800296]\n"
     ]
    }
   ],
   "source": [
    "# gradient values computed by the function\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5ea38",
   "metadata": {},
   "source": [
    "Expected gradients:<br>\n",
    " 0.146561<br>\n",
    " -0.548558<br>\n",
    " 0.724722<br>\n",
    " 1.398003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "8da4b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('ex3data1.mat')\n",
    "\n",
    "X = pd.DataFrame(mat['X']);\n",
    "y = pd.DataFrame(mat['y']);\n",
    "\n",
    "input_layer_size  = 400;  # 20x20 Input Images of Digits\n",
    "num_labels = 10;   \n",
    "\n",
    "reg_param = 0.1;\n",
    "all_theta = oneVsAll(X, y, num_labels, reg_param);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "29ee4fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 96.20 %\n"
     ]
    }
   ],
   "source": [
    "p = predictOneVsAll(all_theta, X).reshape(-1,1)\n",
    "accuracy = np.mean((p == y).astype(int))\n",
    "print('Training Set Accuracy: %.2f %%' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de319d",
   "metadata": {},
   "source": [
    "Expected Accuracy ~ 94.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ba64a2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Saved Neural Network Parameters ...\n"
     ]
    }
   ],
   "source": [
    "#Neural Network Implementation using precomputed parameter vectors.\n",
    "print('Loading Saved Neural Network Parameters ...')\n",
    "params = scipy.io.loadmat('ex3weights.mat')\n",
    "Theta1 = params['Theta1']\n",
    "Theta2 = params['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "94c2ad84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 97.52 %\n"
     ]
    }
   ],
   "source": [
    "p = predict(Theta1, Theta2, X).reshape(-1,1);\n",
    "accuracy = np.mean((p == y).astype(int))\n",
    "print('Training Set Accuracy: %.2f %%' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1623ec",
   "metadata": {},
   "source": [
    "Expected Accuracy ~ 97.5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
